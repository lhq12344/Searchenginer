整个搜索引擎分为两大部分：关键词推荐和网页查询服务。
一.关键词推荐
	1.离线部分：创建汉字和英文词典和词典索引存放在data文件夹中
				细节：要得到词频并且去掉垃圾词
	2.在线部分：开启服务器后先读取字典和索引文件储存到内存
				字典存储类型为vector<pair<string,int>>
				字典索引类型为unorder_map<string,set<int>>
			   wf作为api网关，将客户端的请求发送给对应的微服务（关键词和网页）
			   	关键词微服务接收到用户请求后，使用分词将请求分词后在对应索引里查找
				将所有查询结果汇总去重
				接下来使用最短编辑距离算法找到最大相似度的n个结果并且返回json

				srpc微服务指令	：srpc_generator protobuf wordsearch.proto . 
								protoc -I. --cpp_out=. pagesearch.proto 2>&1 | sed -n '1,200p'
二.网页查询
	1.离线部分：创建网页搜索库和网页偏移库
				细节：网页清洗
					网页去重（simhasher）
	2.在线部分：
				用户输入分词并且计算权重
				查倒排索引，取出交集（包含所有分词的page）
				计算内积大小并且排序


关键技术：
1.中英文分词原理
2.最短编辑距离
2.simhasher文本相似度算法。网页去重
3.向量空间模型（TF‑IDF + 余弦相似度）
4.LRU缓存
	每次得到offset后通过打开磁盘文件ifstream ifs("../../Make_Page/page/text.dat", ios::binary);
	获取文章内容比较耗时。加入缓存保存。一般的缓存有三种类型：FIFO、LRU，LFU。
	缓存的实现有四种思路：1）redeis 优点是跨进程、跨主机共享数据自带持久化与过期机制支持丰富的数据结构（hash、list、set 等）。
							缺点是网络通信开销（TCP/HTTP）较大需维护连接池、序列化依赖外部服务（可用性风险
						2）公共缓存 优点是内存访问效率极高（纳秒级）命中率高（集中式存储）。
							缺点多线程竞争同一资源，需要加锁保护，加锁可能导致性能瓶颈（尤其写操作）
						3）线程私有缓存 优点是每个线程独立缓存，无锁访问，无竞争，延迟极低。 
							缺点是命中率低（缓存碎片化）线程间数据不一致，需要同步机制
						4）双缓存（在线程缓存的基础上，每个线程两个缓存）
							优点是读写分离：一个缓存负责查询，一个负责后台同步。提升读性能、减少锁竞争，可在后台异步更新数据，一个负责查询工作，一个负责同步工作。
							缺点是实现复杂（需要双缓存切换策略） 内存占用增加一倍
	因为使用了wf异步回调的框架。线程私有缓存和双缓存使用不了。决定使用公共缓存。

	另外wf框架提供了WFResourcePool类。但是该类的使用类似于linux的slab高速缓存，既为了避免频繁申请和销毁数据，提前申请n个某类型的数据放入资源池中。按需拿去和放回。

5.倒排索引的数据类型更换：
	哈希表（unordered_map）的特点是：
		通过哈希函数定位桶，时间复杂度 O(1)；
		但无序、不支持范围查询、不易维护顺序或统计；
		读写的局部性较差，不适合频繁磁盘 I/O。	
	如果系统需要频繁统计、排序、范围查询、批量写入或冷热分层，那么树结构更合适。
	
	树形结构对比：
	B+树：
		优点：有序、磁盘友好、范围查询快	
		缺点：插入、删除比哈希慢一点	关系型数据库、文件系统索引
	字典树（Trie）：
	    优点：	前缀搜索快，可支持自动补全	
		缺点：占内存大，节点稀疏时浪费严重	搜索引擎前缀匹配、拼写纠错
	LSM 树（Log-Structured Merge Tree）	
		优点：写入非常高效（顺序写），适合批量读写与持久化	
		缺点：读时需合并多层（稍慢）	NoSQL数据库（如LevelDB、RocksDB），搜索引擎索引存储

	我们更换倒排索引的数据结构为LSM（自己实现）

5.引入数据库FAISS
	5.引入数据库FAISS
	1）首先需要引入FastText。FastText是谷歌开源的用于高效学习单词表示和句子分类的库。我们使用FastText来计算网页文档的向量

​	前提准备：准备一份文本文档来训练模型

​	fasttext::FastText model;model.loadModel("./page/small_model.bin");

​	 2）然后计算我们网页文档的内容的向量，并且保存为文本格式。在微服务启动后读取文本并且将文档的向量存入FAISS数据库。（要进行jieba分词、使用同样的FastText模型计算向量、L2归一化处理）

    3）当客户输入句子后，进行jieba分词、使用同样的FastText模型计算向量、L2归一化处理。然后在FAISS数据库中查找与客户输入最相近的文档docid（FAISS存向量是线性结构，我们需要按照docid存入、读取）最后返回。

优化：使用FAISS并没有我们使用TF-IDF向量化后直接查包含关键词的文档  准确。
	因为Faiss 返回的结果不是看文章是否“包含关键词”，而是看**语义相似度（向量内积或余弦相似度）**是否高。
	因此，有关键词 ≠ 向量空间里相似。
	优化方向，可以修改L2归一化为TF-IDF来提高准确度，还有训练质量更加好的FastText模型。